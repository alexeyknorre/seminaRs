---
title: "Узнаём самый убийственный регион России: несколько приёмов работы с данными в R"
author: "Алексей Кнорре"
output:
  html_document:
    df_print: paged
---

В этом R Notebook описана последовательность работы с данными, которая позволяет с помощью данных портала `crimestat.ru` и таблицы о населении регионов России из Википедии узнать, в каких регионах в 2016 году было совершено больше всего убийств с поправкой на количество населения в регионе. В конце я интерактивно визуализирую результаты (количество убийств на 100 000 человек населения по каждому региону России) с помощью Shiny (но для этого потребуется RStudio, поскольку Shiny нельзя встроить в R Notebook).

Последовательность шагов следующая. Сначала мы выгружаем (скрэпим) таблицу с населением регионов из страницы Википедии с помощью библиотеки `rvest`. После этого парсим XML-файл с данными о зарегистрированных убийствах, скачанный с сайта `crimestat.ru`, с помощью библиотеки `xml2`. Затем мы сличаем две таблицы (мёрджим), но поскольку имена регионов не совпают, используем нечёткое сличение (fuzzy match) с помощью библиотеки `stringdist`. В итоге мы получаем таблицу, которую визуализируем с помощью `Shiny`.  

Не забываем установить нужные библиотеки:
```{r eval=F}
install.packages(c("xml2","rvest","stringdist"))
```

И загружаем их:
```{r warning=F}
library(xml2)
library(rvest)
library(stringdist)
```


### Шаг 1. Данные о населении регионов России

Обычно такие данные берутся напрямую с сайта Росстата, но мы для интереса попробуем их соскрэпить со страницы Википедии. Для этого воспользуемся библиотекой `rvest`. Эта библиотека позволяет прямо в R вытаскивать нужные куски HTML-страниц и сразу преобразовывать их в датафрейм. 

Сначала сохраним в переменную адрес страницы:
```{r}
wiki_url <- "https://ru.wikipedia.org/wiki/%D0%A1%D1%83%D0%B1%D1%8A%D0%B5%D0%BA%D1%82%D1%8B_%D0%A0%D0%BE%D1%81%D1%81%D0%B8%D0%B9%D1%81%D0%BA%D0%BE%D0%B9_%D0%A4%D0%B5%D0%B4%D0%B5%D1%80%D0%B0%D1%86%D0%B8%D0%B8"
```

После этого сохраним XPath нужной нам таблицы. XPath -- это язык запросов к XML-документам, который позволяет донести до программы, какой именно раздел HTML-документа нам нужен. Его можно получить либо с помощью Инструментов разработчика в любом современном браузере, либо с помощью инструмента SelectorGadget.

Вот наш XPath, который ведёт к искомой таблице населения:
```{r}
wiki_xpath <- '//*[@id="mw-content-text"]/div/table[4]'
```

Теперь нам нужно, чтобы `rvest` прочитал HTML-страницу по сохранённому адресу, выделил по XPath нужную нам таблицу сохранил её в виде датафрейма. Всё это делает следующий код:

```{r}
wiki_table <- wiki_url %>% read_html() %>% html_node(xpath = wiki_xpath) %>% html_table()
```

```{r}
wiki_table
```

Таблица избыточная для нашей задачи. Уберём лишние колонки и переименуем их:
```{r}
wiki_table <- wiki_table[,c(2,5,6)]
names(wiki_table) <- c("region", "area", "population")
```
А еще у нас есть строки с пустыми значениями, а перед числом населения стоит Юникод. Кроме того, в таблице с регионами у нас оказалась Российская Федерация, которую тоже нужно убрать.


```{r}
# Оставляем наблюдения без пропущенных значений
wiki_table <- wiki_table[complete.cases(wiki_table),]
# Делаем нормальный столбец с населением
wiki_table$population <- as.numeric(gsub("[^0-9\\.]", "", wiki_table$population))
# Удаляем строку с Российской Федерацией
wiki_table <- wiki_table[!grepl("Российская Федерация", wiki_table$region),]
wiki_table
```

Ура, у нас есть чистая таблица с населением России по регионам. Перейдём теперь к данным о преступности.

### Шаг 2. Готовим данные по преступности (убийствах) в регионах России.

Чтобы получить статистику, идём на сайт crimestat.ru, заходим на вкладку "Открытые данные" и там выбираем "Зарегистрировано убийств и покушений на убийство...", выгружаем через кнопку "XML". И нам сохранится файлик, который для репликации этого документа нужно положить в ту же папку, где и данный документ. Я переменовал файл в `crime_stat_105+.xml` для удобства. Его можно попробовать открыть Блокнотом и посмотреть, что внутри. Давайте сделаем это с помощью R:

```{r}
crimes_xml <- read_xml("data/crimestat_105+.xml")
# Извлекаем всё, что находится под нодами <row>:
rows <- html_nodes(crimes_xml,  xpath = "//row/*")

# Это названия значений:
head(xml_name(rows))
# Это сами значения
head(xml_text(rows))
```

Видим, что в файле есть количество преступлений для каждого региона и каждого отчётного периода (его начала и конца), но в "грязном" виде: они не упорядочены по 4, а идут всплошную. Поэтому мы хитро перевёдем значения в матрицу, где должно быть не больше 4 переменных, то есть говорим, чтобы R делал это по строкам (byrow = T, иначе путается порядок), и эксплицитно задаём 4 колонки:

```{r}
crimes <- matrix(xml_text(rows), byrow = T, ncol = 4)
head(crimes)
# Теперь переводим в датафрейм
crimes <- data.frame(crimes, stringsAsFactors = F)
names(crimes) <- c("crimes", "period_start", "region", "period_end")
crimes
```

Видим, что в данных есть много лет. Оставим только 2016 год:
```{r}
crimes <- crimes[which(crimes$period_start == "2016-01-01" &
                         crimes$period_end == "2016-12-01"),]
```

А поскольку мы оставили только 2016 год, сами периоды тоже можем выкинуть:

```{r}
crimes$period_start <- NULL
crimes$period_end <- NULL
```

Приводим в порядок тип переменной и убираем всю Россию и федеральные округа:

```{r}
crimes$crimes <- as.numeric(crimes$crimes)
crimes <- crimes[!grepl("Российская Федерация|+ФО+", crimes$region),]
crimes
```
Красота, теперь у нас есть табличка с данными об убийствах в регионах России в 2016 году. Осталось соединить две таблички.

### Шаг 3. Нечёткое сличение данных

В обоих табличках одинаковое количество строк:
```{r}
nrow(crimes)
nrow(wiki_table)
```

Но есть проблема: регионы по-разному названы. Что делать?
```{r}
data.frame(crimes = crimes$region, wiki = wiki_table$region)
```

#######################################
# <<< FUCK YEA FUZZY MATCHING!!! >>>  #
#######################################

Можно перекодировать вручную, но есть способ автоматизировать это с помощью библиотеки для вычисления дистанции между двумя строками.
Попробуем это сделать для Республики Саха-Якутия из регионов по преступлениям...
```{r}
crimes$region[1]
```

Высчитываем близость всех других регионов из таблицы Википедии.
```{r}
dists <- stringdist(crimes$region[1], wiki_table$region)
dists
```

Делаем это красиво и наглядно. Чем меньше distance, тем более похожа строка
```{r}
names(dists) <- wiki_table$region
data.frame(distance = dists[order(dists)])
```

Машина справляется, но не всегда. Важно максимально очистить названия.

```{r}
#Убираем слово "Республика"
crimes$region <- gsub("Республика", "", crimes$region)
# Удаляем скобки с цифрами
wiki_table$region <- gsub("\\[|\\]|[0-9]", "", wiki_table$region)
```

Ну теперь можно и цикл сделать, чтобы перебрать все регионы.

```{r}
# Создаём пустую переменную для матчинга имени другого региона
crimes$wiki_region_match <- NA

for (i in 1:nrow(crimes)){
  dists <- stringdist(crimes$region[i], wiki_table$region)
  names(dists) <- wiki_table$region
  crimes$wiki_region_match[i] <- names(dists[order(dists)][1])
}
```

Готово. Объединяем данные:
```{r}
df <- merge(crimes, wiki_table, by.x = "wiki_region_match", by.y = "region")
```

Убираем ненужные колонки:
```{r}
df <- subset(df, select = -c(region) )
names(df)[1] <- "region"
df
```

Всё, мы получили нужный датасет. Сохраняем:
```{r}
write.csv(df, "data/murder_crimes_by_regions.csv", row.names = F)
```

Эти данные мы используем для интерактивной визуализации в Shiny. К сожалению, её нельзя вставить в R Notebook, поэтому нужно скачать [архив](https://github.com/alexeyknorre/workshop_undone_2018) на Github зелёной кнопкой "Clone or download - Download ZIP", распаковать куда-нибудь, и в папке запустить файл `2app.R` через RStudio.
